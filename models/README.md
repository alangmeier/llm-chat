# TODO
- [ ] Check which models are supported by llama-cpp (https://github.com/ggerganov/llama.cpp#description)
- [ ] HuggingFace procedure to download GGUF models, or generate GGUF
- [ ] [`TheBloke`](https://huggingface.co/TheBloke)
- [ ] models
    - https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF
    - https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF
    - others ? (e.g. mistral v0.2)