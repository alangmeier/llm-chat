---
title: Personal CPU-powered AI Chat-Assistant
author: AndrÃ© Langmeier
date: 09 January 2024
keywords: [ai, llm, chatbot, llama-cpp, langchain, chainlit, cpu]
---

# Personal CPU-powered AI Chat-Assistant

This repository 

Implementation of a personall LLM assistant
- [ ] A word on it, why, how it works (on CPU)

## Some demonstrations
- [ ] A video/GIF of the LLM in action

## Setup configuration and installation
List of main components + some words on them + how to install them :
- [ ] Models (`TheBloke` on HuggingFace and GGUF models -> models/README.md)
- [ ] Llama-cpp (does not support async calls)
- [ ] Langchain (LCEL)
- [ ] Chainlit (`make_async` for Llama-cpp models)
- [ ] `.local/share/applications/llm_chat.desktop` with explainations for icons as well

## TODO
- [ ] `.gitignore`
- [ ] Modification of `chainlit.md` as Welcome page for the chat
- [ ] Chainlit chat customization
- [ ] Memory buffer
- [ ] Some other models ?
- [ ] RAG implementation